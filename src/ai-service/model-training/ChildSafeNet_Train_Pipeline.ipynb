{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNNWYQct0tZUdV/vG4WfYEB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["ChildSafeNet - Training Pipeline (URL Classifier)\n","Notebook này train 1 file pipeline (TF-IDF + Model) để tránh mismatch khi deploy. Mặc định train theo dataset malicious_phish.csv (5 nhãn). Nếu bạn có thêm dataset adult_urls.csv và gambling_urls.csv thì có thể merge để ra nhãn Adult/Gambling."],"metadata":{"id":"9AaokrPw2rQQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xh_IW9aF2jNf"},"outputs":[],"source":["!pip -q install scikit-learn joblib pandas numpy"]},{"cell_type":"code","source":["import re, pandas as pd\n","\n","def parse_domains_txt(path):\n","    domains = []\n","    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n","        for line in f:\n","            line = line.strip()\n","            if not line or line.startswith(\"#\"):\n","                continue\n","\n","            # hosts style: \"0.0.0.0 domain.com\" or \"127.0.0.1 domain.com\"\n","            parts = line.split()\n","            if len(parts) >= 2 and re.match(r\"^\\d+\\.\\d+\\.\\d+\\.\\d+$\", parts[0]):\n","                dom = parts[1]\n","            else:\n","                dom = parts[0]\n","\n","            dom = dom.lower()\n","            dom = re.sub(r\"^https?://\", \"\", dom)\n","            dom = re.sub(r\"^www\\.\", \"\", dom)\n","            dom = dom.strip().strip(\"/\")\n","            if dom and \".\" in dom and \" \" not in dom:\n","                domains.append(dom)\n","\n","    # unique\n","    return sorted(set(domains))\n","\n","def domains_to_csv(domains, label, out_csv):\n","    df = pd.DataFrame({\n","        \"url\": [\"https://\" + d for d in domains],\n","        \"label\": [label] * len(domains)\n","    })\n","    df.to_csv(out_csv, index=False)\n","    print(f\"Created {out_csv} with {len(df)} rows\")\n","\n","# --- run ---\n","adult_domains = parse_domains_txt(\"adult_domains.txt\") if \"adult_domains.txt\" in uploaded else []\n","gambling_domains = parse_domains_txt(\"gambling_domains.txt\") if \"gambling_domains.txt\" in uploaded else []\n","\n","if adult_domains:\n","    domains_to_csv(adult_domains, \"adult\", \"adult_urls.csv\")\n","if gambling_domains:\n","    domains_to_csv(gambling_domains, \"gambling\", \"gambling_urls.csv\")"],"metadata":{"id":"F4YMhda224zs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","import joblib\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","\n","def clean(u: str) -> str:\n","    u = str(u).strip().lower()\n","    u = re.sub(r\"\\s+\", \"\", u)\n","    u = re.sub(r\"^https?://\", \"\", u)\n","    u = re.sub(r\"^www\\.\", \"\", u)\n","    u = u.strip(\"/\")\n","    return u\n","\n","# 1) malicious_phish.csv\n","ph = pd.read_csv(\"malicious_phish.csv\")[[\"url\",\"type\"]].dropna()\n","ph[\"url\"] = ph[\"url\"].apply(clean)\n","ph[\"label\"] = ph[\"type\"].astype(str).str.lower()\n","\n","# gộp malware/defacement/spam => phishing\n","ph[\"label\"] = ph[\"label\"].replace({\n","    \"malware\": \"phishing\",\n","    \"defacement\": \"phishing\",\n","    \"spam\": \"phishing\"\n","})\n","ph = ph[ph[\"label\"].isin([\"benign\",\"phishing\"])][[\"url\",\"label\"]]\n","\n","# 2) adult_urls.csv (optional)\n","dfs = [ph]\n","if os.path.exists(\"adult_urls.csv\"):\n","    ad = pd.read_csv(\"adult_urls.csv\")[[\"url\",\"label\"]].dropna()\n","    ad[\"url\"] = ad[\"url\"].apply(clean)\n","    ad[\"label\"] = ad[\"label\"].astype(str).str.lower()\n","    ad = ad[ad[\"label\"].isin([\"adult\",\"benign\"])][[\"url\",\"label\"]]\n","    dfs.append(ad)\n","\n","# 3) gambling_urls.csv (optional)\n","if os.path.exists(\"gambling_urls.csv\"):\n","    ga = pd.read_csv(\"gambling_urls.csv\")[[\"url\",\"label\"]].dropna()\n","    ga[\"url\"] = ga[\"url\"].apply(clean)\n","    ga[\"label\"] = ga[\"label\"].astype(str).str.lower()\n","    ga = ga[ga[\"label\"].isin([\"gambling\",\"benign\"])][[\"url\",\"label\"]]\n","    dfs.append(ga)\n","\n","df = pd.concat(dfs, ignore_index=True).drop_duplicates(\"url\")\n","\n","print(\" Label counts:\", Counter(df[\"label\"]))\n","print(\" Total rows:\", len(df))\n","\n","X = df[\"url\"].values\n","y = df[\"label\"].values\n","\n","X_tr, X_te, y_tr, y_te = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")\n","\n","pipe = Pipeline([\n","    (\"tfidf\", TfidfVectorizer(\n","        analyzer=\"char_wb\",\n","        ngram_range=(3,5),\n","        max_features=80000,\n","        min_df=2\n","    )),\n","    (\"clf\", LogisticRegression(\n","        max_iter=3000,\n","        n_jobs=-1,\n","        class_weight=\"balanced\"\n","    ))\n","])\n","\n","pipe.fit(X_tr, y_tr)\n","pred = pipe.predict(X_te)\n","\n","print(\"\\n classes_:\", pipe.classes_)\n","print(\"\\n report:\\n\", classification_report(y_te, pred))\n","\n","joblib.dump(pipe, \"childsafenet_pipeline.joblib\")\n","print(\"\\n Saved: childsafenet_pipeline.joblib\")"],"metadata":{"id":"8mEpfNsR2_Z2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def test_url(u):\n","    u2 = clean(u)\n","    proba = pipe.predict_proba([u2])[0]\n","    idx = int(np.argmax(proba))\n","    return {\n","        \"url\": u,\n","        \"pred\": pipe.classes_[idx],\n","        \"score\": float(proba[idx]),\n","        \"all\": {c: float(p) for c,p in zip(pipe.classes_, proba)}\n","    }\n","\n","tests = [\n","    \"https://www.google.com\",\n","    \"https://www.wikipedia.org\",\n","    \"https://pornhub.com\",\n","    \"https://bet365.com\",\n","    \"https://testsafebrowsing.appspot.com/s/phishing.html\"\n","]\n","\n","for t in tests:\n","    r = test_url(t)\n","    print(\"\\n---\", r[\"url\"])\n","    print(\"pred:\", r[\"pred\"], \"score:\", round(r[\"score\"], 4))\n","    print(\"all:\", {k: round(v,4) for k,v in r[\"all\"].items()})"],"metadata":{"id":"HwCiLxlf3EkL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"childsafenet_pipeline.joblib\")"],"metadata":{"id":"4oQsFISg3IQC"},"execution_count":null,"outputs":[]}]}